# Befor API

The Beftigre Orchestrator (Befor) is for the cloud tier and analysis of MCA.
Befor API is a jar file which can be run as a GUI tool or from the command line as an API.

See [beftigre-mca.appspot.com](http://beftigre-mca.appspot.com/) for Befor Documentation.

This project was packaged using the [NetBeans Java IDE](https://netbeans.org/).

### After Cloning the project

Run the jmeter-setup.jar to download ApacheJMeter dependencies and setup its necessay files.<br/>
Use the snippet below to execute in command prompt to view stages of the setup process:

```
 java -jar jmeter-setup.jar
```


### Running the API

#### 1. Installation

The Beftigre Orchestrator (Befor) API can either be executed through the command prompt using the API’s commands or as a graphical user interface tool.
Befor API, is bundled as BEFtigreOR.jar. To run Befor tool, the jar can be executed directly by double-clicking it.
To run the APIs via command prompt, the befor argument can be parsed to the command execution as follows:

```
 java -jar BEFtigreOR.jar befor
```

To see the Befor commands and how to use them, run the help command: by simply typing `help`


#### 2. Directories and Files

After starting up the tool or the command line, some required directories and files are created for the test. These are:

 * _/logs_ directory: is where test generated logs (.log) are stored, logs from the mobile device (i.e. generated by Band API) can be placed here.
 * _/results_ directory: is where the data files (.dat) or result of full-tier analyser (.csv) are stored. The data files are the product of analysis on the files in logs directory.
 * _/results/plot_ directory: is where the graph files (.png) are stored when plotted.
 * _/files_ directory: All created template files (such as _slow_, _TestPlan.jmx_, _sigar.zip_) are stored in the files directory. The template files are the files used to setup the serve test process.
 * _slow_ file: is copied to the server by Befor setup command and used (remotely) to issue commands on Linux TC utility which simulate slow/varying network conditions (by setting bandwidth and latency parameters).
 * _TestPlan.jmx_ file: is used (locally) to setup a jmeter test which contains PerfMon metrics collector as a listener, so as to receive CPU and memory usage metrics from the server.
 * _sigar.zip_ file: is copied to and unzipped at the server by Befor and used (remotely) to compile and start the CPUMemoryAvailServer which computes available cloud CPU and memory of the server prior to test.

Other files generated by Befor during setup (and stored in the files directory) are:

 * _settings.befor_ file: is generated to store the connection and test parameters (presented in section 3) when the save button is clicked.
 * _BandwidthLatencyServer.java_ file: is generated when ‘Install setup files operation’ is triggered (see section 4), after being generated it is then copied to and compiled on the server.
 * _CPUMemoryAvailServer.java_ file: is also generated, copied to and compiled on the server at the same time as BandwidthLatencyServer.java file. However, CPUMemoryAvailServer compiles and executes with sigar libraries (from _sigar.zip_) on the classpath.


#### 3. Setting Connection and Test Parameters

Prior to performing any server monitoring and metrics collection operations, the connection and test parameters are required by the API to establish a connection point to the server.
The connection parameters are a pem file, host IP address, port number and the root user of the server.
Test parameters are jmeter directory (required for Perfmon metrics collector), BandwidthLatency port (required to set up a socket connection between the BandwidthLatencyServer and BandwidthLatencyClient), and CPUMemory port (required to set up a socket connection between the CPUMemoryAvailServer and CPUMemoryAvailClient).

Important Note: All ports used within the API setup must be configured in EC2 security groups. Default ports are presented in the table below.
In EC2 the _Source_ for each port setting can be left as 0.0.0.0/0

| Port  | Protocol | Source     | Client component            | Server component         |
|-------|----------|------------|-----------------------------|--------------------------|
| 22    | TCP      | 0.0.0.0/0  | Beftigre API                | EC2 server instance      |
| 8080  | TCP      | 0.0.0.0/0  | Jmeter Test plan            | EC2 server instance      |
| 4848  | TCP      | 0.0.0.0/0  | PerfMon Metrics Collector   | PerfMon Server Agent     |
| 1     | UDP      | 0.0.0.0/0  | `BandwidthLatencyClient`    | `BandwidthLatencyServer` |
| 2     | UDP      | 0.0.0.0/0  | `CPUMemoryAvailClient`      | `CPUMemoryAvailServer`   |
| Any port,<br>e.g. 3 |	TCP | 0.0.0.0/0 | An offloadable task on<br> the mobile device | An offloadable task on<br> the server |

The connection and test parameters can be set using the `params` command of the API.


#### 4. Server Monitor Operations

The server monitor operations (with commands) are presented below:

 * Install setup files operation (`setup` command): involves the installation of all files required for the test process. The setup process is as follows:

    * The setup feature first creates and compiles BandwidthLatencyServer and CPUMemoryAvailServer socket programs on the server using the BandwidthLatency port and CPUMemory port provided in the test parameters (see table above).
      Recall from section 2, that sigar libraries (from sigar.zip) are used in classpath for setting up CPUMemoryAvailServer.
    * The setup then downloads the ServerAgent monitor zip from jmeter repository and extracts on the server.
    * Next the slow file used for network simulation (see section 2) is copied to the server.
    * Finally Linux stress utility is installed for simulation of CPU and memory load on the server.

    In total six files/programs are used to setup the server for Beftigre test (i.e. BandwidthLatencyServer, CPUMemoryAvailServer and sigar API, ServerAgent, slow, stress).

 * Cleanup files operation (`cleanup` command): is used to uninstall or remove all setup files.

 * Setup offload tasks operation (`offload` command): is used to setup and run offloadable tasks of an MCA on the server. 

    * To setup the offloadable tasks on the server, the operation takes a zip file as input. 
    * The zip provided is composed of the class file(s) of the offloadable task (including any required libraries). The offload operation extracts the zip on the server. 
    * Furthermore, to run the offloadable task on the server, the name of the main class is passed to the run function of the offload operation. 
    * Note that the main class has to be a server socket application, and the port used by the class must be made public and accessible by the mobile application. 

 * Set simulation params operation (`simulate` command): is used to set up the parameters used to simulate slow network, and CPU and memory load.

 * Start server monitors operation (`start` command): is used to launch tasks for monitoring server resources – using the four setup processes (associated with Setup/Install operation).
   In other words, i) BandwidthLatencyServer, CPUMemoryAvailServer, and ii) ServerAgent are started alongside the simulation processes – iii) slow and iv) stress utilities, using the provided simulation parameters from the simulation operation.

 * Stop server monitors operation (`stop` command): is used to stop all monitoring processes.


#### 5. Metrics Collector Operations

The metrics collector operations (with commands) are presented below:

 * Edit .jmx test plan operation (`editplan` command): is used to edit the TestPlan.jmx file which contains the jmeter test plan containing PerfMon metrics collector listener used to retrieve CPU and memory usage metrics from the server.

 * Start metrics collector operation (`collect` command): is used to start metrics collector using the test plan created.


#### 6. Full-tier Analyser Operations

The full-tier analyser operations (with commands) are presented below:

 * Extract results operation (`extract` command): is used to compute the results of the test from the log files, and store the results in dat files in the _/results_ directory. From the tool logs are first selected using the _Select Logs_ button.

 * Plot operation (`plot` command): is used to plot any combination of the .dat files in a graph. Graphs are stored as png files in _/results/plot_ directory.


#### 7. `auto`mating the Full-tier Test

auto is Beftigre's test automation command which is used to automate the Beftigre full-tier testing of mobile (Band) and cloud (Befor) tiers.
This makes it easy to repeat experiments on the Beftigre Framework.
As shown in the snippet below, the test automation is initiated by calling the auto command of Befor API with the following three required arguments, and an optional fourth;

`auto auto_script adb_dir reruns interleave`<br>
`auto "C:\script.auto" "C:\path\to\Android\sdk\platform-tools" 4 40`

 * first argument: the auto script file (.auto)
 * second argument: the full path to adb.exe (i.e. Android Debug Bridge)
 * third argument: the number of reruns of the experiment
 * fourth argument: the interleave (in seconds) between reruns

The purpose of the interleave argument is to allow the BaseService of Band API to complete execution – as this is necessary for full-tier evaluation.
An auto script file must specify commands useful for full-tier test. See the format below.

Since the file is for _full-tier test_, the auto script only supports commands for testing. Thus, the result analysis is not handled by the command. 

 * the script file supports five Befor commands relevant for _testing_ the cloud tier: `params`, `offload`, `simulate`, `start`, `collect`, and `stop`. 
 * and an `am` command which is used with the adb.exe to launch the test on the mobile tier.

Sample auto Script file:

```
params pemfile ip port user jmeter blport cmport
offload -s mainclass
simulate bandwidth bandwidthType latency cpuload memload timeout
simulate bandwidth bandwidthType latency cpuload memload timeout
simulate bandwidth bandwidthType latency cpuload memload timeout
start
collect
am instrument -w -e class rs.pedjaapps.Linpack.LinpackTest rs.pedjaapps.Linpack.test/android.test.InstrumentationTestRunner
stop
```

The required commands for constructing the script file to execute `auto` command are `params`, `offload`, `simulate` and `am`. One or more lines of `simulate` can be provided. 
`start`, `collect`, and `stop` are optional. As they do not require any argument they are automatically handled by `auto` command in Befor API.


##### How to obtain the right am command:

`auto` requires that the test project is already installed on the target devices prior to running the test. This is a prerequisite for executing android test via command line.
The application project and test project is automatically installed on first execution from Android studio. To check that a device is connected use `adb devices` command. 
Firstly, ensure that the command line directory is changed to the adb location, e.g.

```
cd C:\Users\Chinenyeze\AppData\Local\Android\sdk\platform-tools
```
Then enter
```
adb shell pm list instrumentation
```

The above command gives a directive of the test projects installed on the connected device, in the format below;
```
instrumentation:rs.pedjaapps.Linpack.test/android.test.InstrumentationTestRunner (target= rs.pedjaapps.Linpack)
```
From the above output the instrumentation points to `[test package]/[runner class]` and the target specifies the `[application package]` of the installed app to be evaluated. 
Further useful adb documentation can be found [here](https://developer.android.com/studio/test/command-line.html).

Given that the class of the test code is rs.pedjaapps.Linpack.LinpackTest, then the am command for auto script in Befor API can be constructed as follows;

Format:
```
am instrument -w -e class [test code class] [test package]/[runner class]
```
E.g.:
```
am instrument -w -e class rs.pedjaapps.Linpack.LinpackTest rs.pedjaapps.Linpack.test/android.test.InstrumentationTestRunner
```


### Dependencies

 * [JDK v1.8.0_112 x64](http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html)
 * [SIGAR API v1.6.4](https://support.hyperic.com/display/SIGAR/Home)
 * [Apache JMeter v3.1](http://jmeter.apache.org/download_jmeter.cgi)
 * [Linux Traffic Control Utility](https://linux.die.net/man/8/tc)
 * [Stress v1.0.4](http://people.seas.harvard.edu/~apw/stress/)
 * [JavaPlot v0.5.0](http://javaplot.panayotis.com/index.html)
 * [RSyntaxTextArea v2.6.0](http://bobbylight.github.io/RSyntaxTextArea/)
 * [JSch v0.1.54](http://www.jcraft.com/jsch/)


### Package Structure

The package structure of Befor API is as follows:

 * `analyser`: contains the classes for full-tier analysis.

    * MetricsParser
    * Plotter
    * PowerParser
    * Summariser

 * `collector`: contains the classes for cloud tier metrics collection during the full-tier test.

    * BandwidthLatencyClient
    * CPUMemoryAvailClient
    * JmxReader
    * PerfmonCollector

 * `helper`: contains the helper classes and files, and the class (Cmd) for the command interface.

    * Cmd
    * FileCreator
    * Helper
    * _TestPlan.jmx file_
    * _rand & slow files_ - traffic control helper files
    * _sigar.zip file_
    * _png files_

 * `monitor`: contains the classes for cloud-tier resource monitoring.

    * BandwidthLatencyServer
    * CPUMemoryAvailServer
    * EC2Server
    * _sigar library_

 * `ui`: contains classes for GUI interface - i.e. the tool.

    * EditTestPlan
    * GraphViewer
    * Help
    * Orchestrator
    * SimSettings


### Author

Samuel Chinenyeze <sjchinenyeze@gmail.com>


### License

[MIT license](http://opensource.org/licenses/MIT)